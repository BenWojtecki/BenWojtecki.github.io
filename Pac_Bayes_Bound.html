<!doctype html>
<html lang="fr">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>PAC-Bayes Bound - Tutoriel</title>
  <link rel="stylesheet" href="style.css"/>
</head>
<body>
  <!-- Barre de navigation -->
  <nav class="navbar">
    <div class="logo">
      <img src="Ant.jpg" alt="Logo"/>
    </div>
    <ul class="nav-links">
      <li><a href="index.html">Accueil</a></li>
      <li><a href="scientific.html">Scientific interest</a></li>
      <li><a href="portfolio.html">Portfolio</a></li>
      <li><a href="contact.html">Contact</a></li>
    </ul>
  </nav>

  <!-- Contenu du tuto -->
  <div class="container">
    <div class="content">
      <h3>Why this tutorial</h3>
      <p>
        During my journey in Pac Bayes Bound, it was difficult for me to deeply understand concepts behind Pac Bayes Bound and more particulary to understand 
        proofs of theses bounds. I'm just a student in computer science who loved study mathematic apply to computer science. 
      </p>
      <h2>Introduction</h2>
      <p>
        In this tutorial, we’re going to explore the main ideas behind the PAC-Bayes Bound, a powerful tool for understanding and controlling the generalization 
        error of a predictor. First, let’s unpack the name. $\textbf{PAC}$ stands for Probably Approximately Correct. In this setting, a learner receives some training 
        samples and must choose a function, called a hypothesis, to make predictions. The goal is that, with high probability, the chosen hypothesis will have
        a low generalization error when applied to unseen data. In supervised learning, we usually define two main sets: $\mathcal{X}$, the universe of objects
        (our input space). $\mathcal{Y}$, the set of possible labels (our output space). For example, if we look at the spam detection problem: $\mathcal{X}$ 
        would be the set of emails. $\mathcal{Y} = {0,1}$, where 1 means “spam” and 0 means “not spam.” A predictor is simply a function $f:\mathcal{X} \to \mathcal{Y}$ 
        that assigns a label to each input. More generally, we consider a whole family of predictors ${f_\theta : \theta \in \Theta}$, where $\Theta$ represents 
        the parameter space. Each $\theta$ corresponds to a specific predictor. Now, if we take an example pair $(x,y) \in \mathcal{X} \times \mathcal{Y}$.
        If $f(x) = y$, our prediction is correct. Otherwise, it’s an error. To keep track of these errors in a more systematic way, we use a loss function. 
        A $\textbf{loss}$ is a function $\ell : \mathcal{Y}^2 \to [0,+\infty[$ that measures how far a prediction is from the true label. By definition, $\ell(y,y) = 0$, 
        meaning no penalty is given if the prediction is correct.
      </p>

      

      <h2>Notation</h2>
      <p>
        Learning problem can be describe by a tuple ($\mathcal{H}, \mathcal{Z}, \ell$), where $\mathcal{H}$ is hypothesis space with a distance $d_\mathcal{H}$, 
        data space $\mathcal{Z}$ and a loss function $\ell : \mathcal{H} \times \mathcal{Z} \xrightarrow{}\mathbf{R}$. Our objective is to bound the $\mathbf{population}$  
        $\mathbf{risk}$ of a given hypothesis $\textit{h}$ defined as $R_\mathcal{D}(h) = \mathbf{E}_{z\sim \mathcal{D}}[\ell(h, \mathbf{z})]$, where $\mathcal{D}$ denotes
        the unknow data distribution over $\mathcal{Z}$.
        <ul>
          <li>$Lip_b^L$ is the set of bounded L-Lipschitz functions </li>
          <li>For any $\delta \in [0;1]$, with probability $1-\delta$, $j \xrightarrow{} \Delta_\mathcal{S}^2(h)$ is $L(m, \delta)$-Lipschitz, where m is the size of dataset.
            We can read this expression like: The function $\Delta_\mathcal{S}^2(h)$ is continue Lipschitz with a constant, probability at least, $1-\delta$, is bound by $(m,\delta)$.
          </li>
        </ul>
      </p>
      <p>
        $$ R(Q) \leq \hat{R}(Q) + \sqrt{\frac{KL(Q \parallel P) + \ln \frac{2\sqrt{n}}{\delta}}{2n}} $$
      </p>

      <p>
        où :
        <ul>
          <li>$R(Q)$ = risque attendu</li>
          <li>$\hat{R}(Q)$ = risque empirique</li>
          <li>$KL(Q \parallel P)$ = divergence de Kullback-Leibler</li>
          <li>$n$ = nombre d’échantillons</li>
          <li>$\delta$ = probabilité de confiance</li>
        </ul>
      </p>
    </div>
  </div>

  <h2>Preuve — régularité de \(\varphi_S\) et union bound</h2>

  <p><b>Hypothèses.</b><br>
  Soit \(S\) un échantillon de taille \(m\). On définit, pour tout \(h\) dans l'espace des hypothèses \(\mathcal{H}\),
  </p>
  Si une fonction f est L-Lipschitz, alors $g(x) = cf(x)$ est (cL)-Lipschitz. Formellement : $\mid g(h) -g(h')\mid = \mid c\mid\mid f(h) - f(h')\mid \leq \mid c \mid L\|h-h'\|$


  <p style="text-align:center;">
  \[
  \Delta_S^2(h), \qquad \varphi_S(h) := 2m\,\Delta_S^2(h).
  \]
  </p>

  <p>On suppose que pour tout \(\delta'\in(0,1)\), on a la propriété suivante :</p>

  <p style="text-align:center;">
  \[
  \Pr\!\Big( h\mapsto\Delta_S^2(h)\ \text{est}\ L(m,\delta')\text{-Lipschitz} \Big)\;\ge\;1-\delta',
  \]
  </p>

  <p>c'est-à-dire que, avec probabilité au moins \(1-\delta'\),</p>

  <p style="text-align:center;">
  \[
  \forall h,h'\in\mathcal{H},\qquad
  \big|\Delta_S^2(h)-\Delta_S^2(h')\big|
  \le L(m,\delta')\,\|h-h'\|.
  \]
  </p>

  <h3>1. Passage de \(\Delta_S^2\) à \(\varphi_S\)</h3>

  <p>Si, avec probabilité au moins \(1-\delta/2\), la fonction \(h\mapsto\Delta_S^2(h)\) est 
  \(L\!\big(m,\tfrac{\delta}{2}\big)\)-Lipschitz, alors en multipliant par la constante \(2m\) on obtient :</p>

  <p style="text-align:center;">
  \[
  \forall h,h'\in\mathcal{H},\qquad
  |\varphi_S(h)-\varphi_S(h')|
  =2m\,|\Delta_S^2(h)-\Delta_S^2(h')|
  \le 2m\,L\!\Big(m,\tfrac{\delta}{2}\Big)\,\|h-h'\|.
  \]
  </p>

  <p>Ainsi \(h\mapsto\varphi_S(h)\) est \(\alpha(m,\delta)\)-Lipschitz avec</p>

  <p style="text-align:center; font-size: 110%;">
  \[
  \alpha(m,\delta)=2m\,L\!\Big(m,\tfrac{\delta}{2}\Big).
  \]
  </p>

  <h3>2. Union bound avec l'Équation (4)</h3>

  <p>Soit \(E_1 := \{\Delta_S^2 \text{ est } L(m,\tfrac{\delta}{2})\text{-Lipschitz}\}\) et 
  \(E_2 := \{\text{(Équation (4)) est vérifiée}\}\).  
  Alors</p>

  <p style="text-align:center;">
  \(\Pr(E_1)\ge 1-\tfrac{\delta}{2}, \qquad \Pr(E_2)\ge 1-\tfrac{\delta}{2}.\)
  </p>

  <p>Par l'inégalité de Boole (union bound) :</p>

  <p style="text-align:center;">
  \[
  \Pr(E_1\cap E_2) \;\ge\; 1-\delta.
  \]
  </p>

  <h3>3. Conclusion</h3>

  <p>Sur l'événement \(E_1\cap E_2\) (de probabilité au moins \(1-\delta\)) :</p>

  <ul>
    <li>\(\Delta_S^2\) est \(L\!\big(m,\tfrac{\delta}{2}\big)\)-Lipschitz,</li>
    <li>\(\varphi_S\) est \(\alpha(m,\delta)\)-Lipschitz avec 
    \(\alpha(m,\delta)=2m\,L\!\big(m,\tfrac{\delta}{2}\big)\),</li>
    <li>et l'Équation (4) est satisfaite.</li>
  </ul>

  <p>En réarrangeant l'inégalité de l'Équation (4), on obtient donc la borne désirée valable avec probabilité au moins \(1-\delta\).</p>

  <p style="text-align:right;">\(\square\)</p>


  <h2>Petit rappel mathématique</h2>
  <p>Rappelons la dérivée de Radon-Nykodyn, $h(g) = \frac{d\rho}{d\pi}(g) \Leftrightarrow h\rho = h(g)d\pi(g)$</p>. Si $\rho, \pi$, sont sur le même espace 
  mesurable et $\rho$ absolument continue respectivement à $\pi$,  $(\rho << \pi)$.

  <p style="text-align:center;">
    $\mathbf{E}_{y\sim \rho}[\phi(g)] = \int \phi(g)d\rho(g) = \int \phi(g)h(g)d\pi(g) = \mathbf{E}_{g\sim \pi}[h(g)\phi(g)]$
  </p>
  <p>Posons $f(u) = ulog(u)$:</p>

  <p style="text-align:center;">
    $D_f(\rho \| \pi) = \mathbf{E}_{h\sim \rho}f(\frac{d\rho}{d\pi}) = \mathbf{E}_{h\sim \rho}[\frac{d\rho}{d\pi}(h)log(\frac{d\rho}{d\pi}(h))]
    = \mathbf{E}_{h\sim \pi}[log(\frac{d\rho}{d\pi}(h))] = KL(\rho \| \pi)$ On utilise un changement de mesure.
  </p>

  <!-- Script LaTeX MathJax -->
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\\[', '\\]']]
      }
    };
  </script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</body>
</html>
